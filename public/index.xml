<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tommy Ho on Tommy Ho</title>
    <link>/</link>
    <description>Recent content in Tommy Ho on Tommy Ho</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Tue, 10 Sep 2019 00:00:00 -0700</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>A Distributed Scheme for Accelerating Semantic Video Segmentation on An Embedded Cluster</title>
      <link>/publication/iccd-2019/</link>
      <pubDate>Tue, 10 Sep 2019 17:27:46 -0700</pubDate>
      
      <guid>/publication/iccd-2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Nvidia</title>
      <link>/talk/nvidia/</link>
      <pubDate>Sat, 05 Jan 2019 23:27:12 +0800</pubDate>
      
      <guid>/talk/nvidia/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ARGAN</title>
      <link>/project/argan/</link>
      <pubDate>Tue, 01 Jan 2019 16:55:09 +0800</pubDate>
      
      <guid>/project/argan/</guid>
      <description>&lt;p&gt;Image-to-image translation has been a popular topic since the Deep Learning had taken over a important position in research field regarding Computer Vision. In such kind of task, the model will usually learn a mapping &lt;code&gt;G : X → Y&lt;/code&gt; such that the distribution of generated images from &lt;code&gt;G(X)&lt;/code&gt; is indistinguishable from the distribution &lt;code&gt;Y&lt;/code&gt;. What we have achieved in this project is having aids from additional image encoded with input, to assist the model find the mapping more easily to the desired output. Such thought can be written as &lt;code&gt;G : X + Z → Y&lt;/code&gt; . We successfully enrich the complexity of &lt;code&gt;X&lt;/code&gt; with the help of &lt;code&gt;Z&lt;/code&gt;, and map &lt;code&gt;G(X + Z)&lt;/code&gt; with &lt;code&gt;Y&lt;/code&gt; by this implementation. Interesting results are generated by this approach.&lt;/p&gt;

&lt;p&gt;Our project is inspired by SAGOSKATT, which is a campaign held by IKEA meant to produce toys all designed by children for charity.&lt;/p&gt;

&lt;p&gt;The project is also the 3rd prize winner in Final Project Competition of National Tsing Hua University The Cutting-Edge of Deep Learning (CEDL 2017), sponsored by QCT and HTC Health.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Twitter Sarcasm Detection</title>
      <link>/project/twitter-sarcasm-detection/</link>
      <pubDate>Tue, 01 Jan 2019 16:54:46 +0800</pubDate>
      
      <guid>/project/twitter-sarcasm-detection/</guid>
      <description>&lt;p&gt;Precise semantic presentation of a sentence and definitive information extraction are key steps in the accurate processing of sentence meaning, especially for figurative phenomena such as sarcasm, irony and metaphor. Semantic modeling faces a new challenge in social media because grammatical inaccuracy is commonplace yet many previous state-of-the-art methods exploit grammatical structure. For sarcasm detection over social media content, researchers so far have counted on Bag-of-Words, N-grams and etc. In this project, we apply a neural network semantic model for sarcasm detection on &lt;a href=&#34;arxiv.org/abs/1704.05579&#34; target=&#34;_blank&#34;&gt;Twitter sarcasm dataset&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We propose to &lt;strong&gt;combine CNN(1D) with LSTM&lt;/strong&gt; in this project. CNN(1D) extract proper local feature extraction which resembles 1-gram. After the feature extraction, LSTM can fully learn the hidden information behind the context of sequences of higher level features provided by CNN(1D). Such design is often seen in tasks requiring comprehending sequences of images or sounds, such as activity classification or sound classification. We believe that the mixture of CNNs and RNNs can work well also in semantic analysis, as the architecture utilizes both networks’ advantages.&lt;/p&gt;

&lt;p&gt;In order to demonstrate the vaildility of the sarcasm detection model, we designed a GUI interface with keywords searching on Twitter. The system can download keywords-matched tweet immediately from Twitter and detect the sarcasm. The demonstration result can be found in PDF report.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Visual Relationship Prediction via Label Clustering and Incorporation of Depth Information</title>
      <link>/publication/pic-workshop/</link>
      <pubDate>Mon, 31 Dec 2018 20:54:49 +0800</pubDate>
      
      <guid>/publication/pic-workshop/</guid>
      <description>&lt;!-- More detail can easily be written here using *Markdown* and $\rm \LaTeX$ math code. --&gt;
</description>
    </item>
    
  </channel>
</rss>
