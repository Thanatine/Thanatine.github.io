[{"authors":["Hsuan-Kung Yang∗, Tsu-Jui Fu∗, Po-Han Chiang†, Kuan-Wei Ho†, Chun-Yi Lee"],"categories":null,"content":"","date":1568161666,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568161666,"objectID":"d00c9535d6021003bb39a9f96ca1e92a","permalink":"/publication/iccd-2019/","publishdate":"2019-09-10T17:27:46-07:00","relpermalink":"/publication/iccd-2019/","section":"publication","summary":"We present a methodology for enhancing the throughput of semantic video segmentation tasks on an embedded cluster containing multiple embedded processing elements (ePEs). The methodology embraces a scalable master-slave hierarchy and features a global and local key management scheme for allocating video frames to different ePEs. The master ePE divides each video frame into frame regions, and dynamically distributes different regions to different slave ePEs. Each slave ePE executes either a segmentation path or a flow path: the former is highly accurate but slower, while the latter is faster but less accurate. A lightweight decision network is employed to determine the execution path for each slave ePE. We propose a global and local key management scheme to facilitate the execution of the embedded cluster, such that the average processing latency of each frame is significantly reduced. We evaluate the performance of our methodology on a real embedded cluster in terms of accuracy and frame rate, and validate its effectiveness and efficiency for various ePE configurations. We further provide a detailed latency analysis for different configurations of ePEs. Index Terms—embedded cluster, semantic video segmentation, optical flow, decision network, global and local key management.","tags":[],"title":"A Distributed Scheme for Accelerating Semantic Video Segmentation on An Embedded Cluster","type":"publication"},{"authors":[],"categories":null,"content":"","date":1546702032,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546702032,"objectID":"28733b91c180b00b04a852152383bedd","permalink":"/talk/nvidia/","publishdate":"2019-01-05T23:27:12+08:00","relpermalink":"/talk/nvidia/","section":"talk","summary":"","tags":[],"title":"Nvidia","type":"talk"},{"authors":null,"categories":null,"content":"Image-to-image translation has been a popular topic since the Deep Learning had taken over a important position in research field regarding Computer Vision. In such kind of task, the model will usually learn a mapping G : X → Y such that the distribution of generated images from G(X) is indistinguishable from the distribution Y. What we have achieved in this project is having aids from additional image encoded with input, to assist the model find the mapping more easily to the desired output. Such thought can be written as G : X + Z → Y . We successfully enrich the complexity of X with the help of Z, and map G(X + Z) with Y by this implementation. Interesting results are generated by this approach.\nOur project is inspired by SAGOSKATT, which is a campaign held by IKEA meant to produce toys all designed by children for charity.\nThe project is also the 3rd prize winner in Final Project Competition of National Tsing Hua University The Cutting-Edge of Deep Learning (CEDL 2017), sponsored by QCT and HTC Health.\n","date":1546332909,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546332909,"objectID":"b49526041cd160160bbc10273ce80213","permalink":"/project/argan/","publishdate":"2019-01-01T16:55:09+08:00","relpermalink":"/project/argan/","section":"project","summary":"Assist Retrieval Generative Adversarial Networks for Clumsy Drawings","tags":[],"title":"ARGAN","type":"project"},{"authors":null,"categories":null,"content":"Precise semantic presentation of a sentence and definitive information extraction are key steps in the accurate processing of sentence meaning, especially for figurative phenomena such as sarcasm, irony and metaphor. Semantic modeling faces a new challenge in social media because grammatical inaccuracy is commonplace yet many previous state-of-the-art methods exploit grammatical structure. For sarcasm detection over social media content, researchers so far have counted on Bag-of-Words, N-grams and etc. In this project, we apply a neural network semantic model for sarcasm detection on Twitter sarcasm dataset.\nWe propose to combine CNN(1D) with LSTM in this project. CNN(1D) extract proper local feature extraction which resembles 1-gram. After the feature extraction, LSTM can fully learn the hidden information behind the context of sequences of higher level features provided by CNN(1D). Such design is often seen in tasks requiring comprehending sequences of images or sounds, such as activity classification or sound classification. We believe that the mixture of CNNs and RNNs can work well also in semantic analysis, as the architecture utilizes both networks’ advantages.\nIn order to demonstrate the vaildility of the sarcasm detection model, we designed a GUI interface with keywords searching on Twitter. The system can download keywords-matched tweet immediately from Twitter and detect the sarcasm. The demonstration result can be found in PDF report.\n","date":1546332886,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546332886,"objectID":"4a2de085053da6094d07b5dd6ee1edb7","permalink":"/project/twitter-sarcasm-detection/","publishdate":"2019-01-01T16:54:46+08:00","relpermalink":"/project/twitter-sarcasm-detection/","section":"project","summary":"Mixed approach of CNN and LSTM on Twitter Sarcasm Dataset","tags":[],"title":"Twitter Sarcasm Detection","type":"project"},{"authors":["Hsuan-Kung Yang","An-Chieh Cheng∗","Kuan-Wei Ho∗","Tsu-Jui Fu","Chun-Yi Lee"],"categories":null,"content":"","date":1546260889,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546260889,"objectID":"9faaab3b2ff8b211ea69cfde1418d911","permalink":"/publication/pic-workshop/","publishdate":"2018-12-31T20:54:49+08:00","relpermalink":"/publication/pic-workshop/","section":"publication","summary":"In this paper, we investigate the use of an unsupervised label clustering technique and demonstrate that it enables substantial improvements in visual relationship prediction accuracy on the Person in Context (PIC) dataset. We propose to group object labels with similar patterns of relationship distribution in the dataset into fewer categories. Label clustering not only mitigates both the large classification space and class imbalance issues, but also potentially increases data samples for each clustered category. We further propose to incorporate depth information as an additional feature into the instance segmentation model. The additional depth prediction path supplements the relationship prediction model in a way that bounding boxes or segmentation masks are unable to deliver. We have rigorously evaluated the proposed techniques and performed various ablation analysis to validate the benefits of them.","tags":[],"title":"Visual Relationship Prediction via Label Clustering and Incorporation of Depth Information","type":"publication"}]